from mongodb_connector import fetch_user_query, fetch_retrieved_chunks, store_evaluation
from embedding_utils import embed_text
from evaluation.accuracy import compute_accuracy
from evaluation.hallucination import detect_hallucination
from evaluation.relevance import compute_relevance
import numpy as np
from datetime import datetime, timezone


def evaluate_response(query_id: str = None):
    
    query_data = fetch_user_query(query_id)

    if not query_data:
        print("No query data found.")
        return
    
    user_query = query_data['user_prompt']['text'] # User's original query
    ai_response = query_data['ai_response']['text'] # AI-generated response
    retrieved_chunks = fetch_retrieved_chunks(query_data["_id"])
    
    #Convert to embeddings
    query_embed = embed_text(user_query)
    response_embed = embed_text(ai_response)
    chunks_embed = [embed_text(chunk) for chunk in retrieved_chunks]

    metrics = {
        "accuracy": compute_accuracy(
            predicted=ai_response,
            reference_chunks=retrieved_chunks,
            predicted_embedding=response_embed,
            reference_embeddings=chunks_embed
        ),
        "relevance": compute_relevance(
            query_embedding=query_embed,
            response_embedding=response_embed
        ),
        "hallucination": detect_hallucination(
            predicted_response=ai_response,
            retrieved_chunks=retrieved_chunks
        ),
        "timestamp": datetime.now(timezone.utc)  
    }

    store_evaluation(
        query_id=query_data["_id"],
        ai_response=ai_response,
        evaluation_scores=metrics
    )
    print(f"Evaluation stored for query {query_data['_id']}")

# Example: This will be triggered after a query-response pair is generated by the chatbot.
if __name__ == "__main__":
    evaluate_response()
  
